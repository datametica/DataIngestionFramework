tasks:
  - task_name: orders-json-flatten-load-batch
    job_name: json-flatten-orders-batch-ingestion
    input_processor: JsonFlattenBatchProcessor
    is_filename_req_in_target: False
    job_prop_file: gs://bucket-name/property-dir/json-flatten/job_prop.yaml
    column_name_map: gs://bucket-name/misc/ColumnMapping.json
    data_file: gs://bucket-name/data-files/orders_nest.json
    targets:
      - bigquery:
          target_table: gcp_project.dataset_name.orders_nest
          write_disposition: write_append
#          write_method: STORAGE_WRITE_API  #optional - if not provided, DEFAULT will use STREAMING_INSERTS on Streaming pipelines and FILE_LOADS on Batch pipelines.
